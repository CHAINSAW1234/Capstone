# Capstone - VR 교육 시스템: 실시간 피드백을 통한 점차형 학습 모듈

부산대학교 정보컴퓨터공학부 2024 후기 캡스톤 프로젝트입니다. 이 프로젝트는 **실시간 피드백이 가능한 점차형 학습 시스템 모듈**을 개발하여 VR(Virtual Reality)을 활용한 몰입형 교육 환경을 제공합니다.

## 프로젝트 개요
본 프로젝트는 학습자가 현실에서 경험하기 어려운 환경을 가상 공간에서 실습할 수 있도록 지원하며, 실시간 피드백을 통해 학습 효율과 몰입도를 극대화하는 것을 목표로 합니다.  
- **지도교수**: 이명호
- **작성일**: 2025년 2월 21일  

특히, **화재 대피 훈련 시스템**을 모듈화 예시로 구현하여 실생활에서의 응용 가능성을 탐구했습니다.

## 구성원

<div align="center">

| [강원우](https://github.com/201924407) | [조현진](https://github.com/CHAINSAW1234) |
| :---------------------------------------: | :------------------------------------: |
| <img src="https://github.com/201924407.png" width="100"> | <img src="https://github.com/CHAINSAW1234.png" width="100"> |

</div>

## 프로젝트 목표
1. **실시간 피드백 제공**: 사용자의 입력에 따라 즉각적인 피드백(색상 변화, 진동, 음성 안내, 화살표 가이드 등)을 제공하여 학습 경험을 개선.
2. **점차형 학습 설계**: 단계별로 학습 과정을 구성하여 사용자가 순차적으로 실습을 수행하도록 유도.
3. **VR 기반 몰입도 강화**: VR 환경에서 실제와 유사한 경험을 제공하여 학습 효과를 극대화.
4. **화재 대피 훈련 모듈화**: 화재 상황에서의 대피 과정을 VR로 구현하여 실질적인 훈련 시나리오를 제공.

---

## 주요 기능

### 사용자 입력 Task
- **객체 조작**: 객체를 잡고 이동하거나 X, Y, Z 축으로 회전 가능.
- **자동 정렬**: 특정 위치(Snap Zone)에 객체를 놓으면 자동으로 정렬.
- **정확도 평가**: 객체의 위치와 회전을 비교하여 사용자의 수행 정확도를 측정.

### 실시간 피드백 Task
| 기능          | 설명                              | 구현 요구사항                     |
|---------------|-----------------------------------|-----------------------------------|
| 색상 변화     | 올바른 위치 및 각도를 색상으로 표시 | 대비 강한 색상 조합, 실시간 반영   |
| 진동 피드백   | 컨트롤러에서 진동으로 피드백 제공   | 진동 강도 조절, 과도한 진동 방지   |
| 음성 안내     | Task에 따른 음성 가이드 제공       | 적절한 음성 크기, 온/오프 기능 지원 |
| 화살표 가이드 | 올바른 방향을 시각적으로 유도       | 3D 공간에서 동적 조정, 시야 내 표시 |
| 진행도 표시   | 학습 진행률을 퍼센트로 표시        | 실시간 업데이트, UI 최적화         |

### 화재 대피 훈련 시스템
본 프로젝트에서는 모듈화 시스템의 예시로 **화재 대피 훈련 시스템**을 구현했습니다. 이 시스템은 현실적인 화재 상황에서의 대피 훈련을 목표로 하며, 다음과 같은 시나리오와 기능을 포함합니다:

#### 상황 시나리오 (화재 발생 시 대피)
1. **화재 발생 및 초기 상황 인지**
   - 건물 내부에서 화재 경보가 울리며 연기와 불꽃이 발생.
   - 시야가 연기로 흐려지고, 주변 온도가 상승하는 효과 적용.
   - 사용자에게 "화재 발생! 안전하게 대피하세요"라는 음성 안내 제공.
2. **호흡기 보호 조치**
   - 사용자는 근처 물체(헝겊, 수건)를 찾아 물에 적셔야 함.
   - 물에 적신 헝겊을 입과 코에 대는 행동을 수행.
   - 실패 시 연기 흡입으로 화면이 점차 흐려지며 경고 표시.
3. **낮은 자세로 이동 준비**
   - 연기가 상단으로 퍼지므로 사용자는 앉거나 기는 자세로 전환.
   - VR 컨트롤러로 "낮은 포복" 동작을 입력해 이동 시작.
4. **대피 경로 탐색 및 장애물 극복**
   - 연기로 가득 찬 복도에서 비상구 표지판을 따라 이동.
   - 넘어진 가구나 뜨거운 표면 같은 장애물이 나타남.
   - 문 손잡이를 확인해 열지 판단(뜨거우면 다른 경로 탐색).
5. **시간 내 안전 지대 도달**
   - 화재가 확산되며 시간이 줄어드는 상황(예: 5분 제한).
   - 비상구로 탈출하거나 안전한 장소에 도달하면 훈련 완료.
   - 완료 후 대피 시간 및 피드백 출력.

#### 학습자가 익혀야 할 핵심 행동
- **젖은 헝겊을 입에 갖다 대기**: 연기로부터 호흡기를 보호하기 위해 헝겊을 물에 적셔 입과 코를 가림.
- **낮은 포복으로 이동**: 연기가 위쪽으로 퍼지므로 바닥을 기어서 이동하며 안전한 경로 탐색.
- **문 손잡이 확인**: 문이 뜨겁지 않은지 확인하여 화재가 반대편에 있는지 판단.
- **비상구로 이동**: 비상구 표지판을 따라 빠르게 탈출.
- **방화벽 사용**: 방화벽 차폐 시 통과법 숙지.

#### 구현 절차
1. **젖은 헝겊을 입에 갖다 대기**
   - **절차**: 사용자가 헝겊을 잡고 물통에 적신 후 얼굴에 고정.
   - **모듈**: `XRGrabInteractable`로 헝겊과 물통 조작, "젖음" 상태 전환 후 호흡 보호 적용.
   - **피드백**: 물에 젖으면 이펙트 추가, 얼굴에 댈 때 연기 흐림 감소 및 안정적인 숨소리 제공.
2. **낮은 포복으로 이동**
   - **절차**: 컨트롤러로 낮은 자세 입력 후 비상구로 이동.
   - **모듈**: 컨트롤러 높이 감지로 이동 제한, 비상구 Snap Zone 설정.
   - **피드백**: 자세 이탈 시 시야 흐림 및 심박 소리 빨라짐.
3. **문 손잡이 확인**
   - **절차**: 손잡이를 잡고 온도 감지 후 문 열기 여부 결정.
   - **모듈**: `XRGrabInteractable`로 손잡이 조작, 문 열기 동작 구현.
   - **피드백**: 뜨거울 시 열 왜곡 효과 및 진동 피드백.
4. **비상구로 이동**
   - **절차**: 표지판과 화살표를 따라 비상구로 이동.
   - **모듈**: 동적 3D 화살표 가이드로 경로 안내.
   - **피드백**: 거리 음성 안내, 경로 이탈 시 붉은 테두리 점멸.
5. **방화벽 사용**
   - **절차**: 손잡이를 조작해 방화벽 열고 통과.
   - **모듈**: `XRGrabInteractable`로 방화벽 조작.
   - **피드백**: 금속성 문 열림 소리, "안전 구역 접근" 텍스트 표시.

---

## 시스템 아키텍처
- **입력 처리 모듈**: VR 컨트롤러 및 입력 장치의 동작을 감지.
- **데이터 분석 모듈**: 학습자의 수행 패턴 분석 및 성과 기록.
- **실시간 피드백 시스템**: 색상, 진동, 음성, 화살표, 진행도 등을 실시간으로 반영.

---

## 사용된 기술 스택

### 개발 언어
- **C#**: Unity 기반 개발.
- **C++**: 성능 최적화 및 데이터 처리.

### 개발 도구
- **Unity**: 3D 환경 개발 (Unity Editor: 6000.0.32f1).
- **Blender**: 애셋 제작 (화재 환경, 헝겊, 방화벽 등 모델링).
- **Adobe Premiere Pro & Photoshop**: UI 및 시각 자료 제작.

### 사용 장비
- **Oculus Quest 2**: VR 테스트 및 시뮬레이션.

---

## 설치 및 실행 방법

### Prerequisites
- Unity 6000.0.32f1 이상 설치
- Oculus Quest 2 (또는 호환 가능한 VR 기기)
- XR Interaction Toolkit 설치

### 설치방
1. 이 저장소를 클론합니다:
   ```bash
   git clone https://github.com/[Your-GitHub-Username]/[Your-Repo-Name].git
   ```
2. Unity Hub에서 프로젝트를 열고, Assets/Scenes/MainScene을 실행합니다.
3. VR 기기를 연결하고, Oculus Link를 통해 디바이스와 연동합니다.
4. Unity에서 Play 버튼을 눌러 실행합니다.

## 프로젝트 진행 일정
- 중간 보고서 및 평가표 제출: 2025년 3월 24일 (월)
- 최종 보고서 및 평가표 제출: 2025년 5월 26일 (월)
- 졸업과제 발표 심사: 2025년 6월 16일 ~ 6월 20일
- 결과 업로드: 2025년 6월 말 ~ 7월 초

## 참고 문헌
- 최지원 외, (2024). "방사선비상진료 대응 VR교육을 위한 VR교육 모델링 시스템에 관한 연구." 디지털콘텐츠학회논문지, 25(7), 1861-1871.
- 정정환 외, (2024). "방사선학과 학생들의 VR 교육 만족도 조사." 한국콘텐츠학회논문지, 24(7), 473-480.
- 최성, (2021). "VR 기반 프로그램을 활용한 과학적 모형 구성 수업의 개발과 효과." 서울대학교 대학원 박사학위 논문.

## 기여 방법
이 프로젝트는 오픈 소스로 제공되며, 누구나 기여할 수 있습니다. 버그를 발견하거나 새로운 기능을 제안하고 싶다면, 이슈를 등록하거나 풀 리퀘스트를 제출해주세요!

## 라이선스
이 프로젝트는 MIT License 하에 배포됩니다.
